---
title: "Machine Learning Final Project"
date: "Wednesday, August 20, 2014"
output: html_document
---

####Data Hygiene

In first investigating `pml-training.csv`, I noticed that several variables had a large number of null or NA values.  I excluded these variables from my training and testing.  I also excluded the index column and the columns containing time stamps.  In all, the training and testing data sets I used had 56 variables (including `classe`).

####Data Partition

To allow an additional step of cross validation beyond the bootstrapping executed by default in the `caret` package's 'train' function, I spilt `pml-training.csv` into two sets of data, so that I could test models before using them with `pml-testing.csv`.

```
set.seed(3333)
inTrain = createDataPartition(train.complete$classe, p = .6)[[1]]
train.complete.train = train.complete[inTrain,]
train.complete.validate = train.complete[-inTrain,]
```

####Training Models

Given the task of predicting a factor variable (`classe`), I decided to investigate several of the classification methods covered in the video lectures, in particular decision trees, random forests, linear discriminant analysis, and naive Bayes classification.

```
tree <- train(train.complete.train$classe ~ ., method = "rpart", data = train.complete.train)

lda <- train(train.complete.train$classe ~ ., method = "lda", data = train.complete.train)

nb <- train(train.complete.train$classe ~ ., method = "nb", data = train.complete.train)

forest <- train(train.complete.train$classe ~ ., method = "rf", data = train.complete.train)
```

Of the four models initiated above only the decision tree and linear discriminant analysis finished processing in a timely manner.  The random forest and naive Bayes classification both ran for over two hours without finishing.

In researching this issue on the course discussion board, I found a recommendation to use `trainControl()` to:

1.Change the default cross validation method to limit the number of iterations executed with the random forest model fit.

2.Enable parallel processing across my processor's multiple cores.

Using the following R code, I was able to get the random forest to complete in a timely manner.  (The new cross validation method is K-fold cross validation with 4 folds.)

```
rfCtrl = trainControl(method = "cv", number = 4, allowParallel = TRUE, verboseIter = TRUE)

forest <- train(train.complete.train$classe ~ ., method = "rf", data = train.complete.train, trControl = rfCtrl)
```
As we'll see below, the random forest proved to be a very accurate predictor, so I did not further pursue getting the naive Bayes classification to run in a timely manner.

####Out of Sample Error

To estimate out of sample error, I first investigated my various model fits, which can be seen in the *Appendix Figures 1 - 3*.

For the decision tree, it appears the model's accuracy will be in range of .35 to .55.

For the linear discriminant analysis it will be 0.745.

And for the random forest it will be in the range of 0.99 to 0.995.

Then, I used the validation data set (`train.complete.validate`) that I partitioned from the original `pml-training.csv` data set to confirm the out of sample error rates.

Below is the code I used to make predctions for the validation data and calculate ab out of sample error.

```
ptree <- predict(tree,train.complete.validate)
confusionMatrix(train.complete.validate$classe,ptree)

plda <- predict(lda,train.complete.validate)
confusionMatrix(train.complete.validate$classe,plda)

pforest <- predict(forest,train.complete.validate)
confusionMatrix(train.complete.validate$classe,pforest)
```

I ultimately found the following levels of accuracy for the three model types above (I used accuracy as my main measure of out of sample error).

Method|Accuracy
-------------|-------------
Decision Tree|0.4950
Linear Discriminant Analysis|0.7439
Random Forest|0.9975

This shows that the cross validation in the model training did a good job of estimating the out of sample error that would actually be seen in a new data set.

More specific details from the `confusionMatrix()` function for the Linear Discriminant Analysis and the Random Forest can be found in the *Appendix Figures 4 - 5*.  I did not include the Decision Tree, since it's accuracy rate is so low.

As can be seen in the table above, the random forest provided the most accurate classification with the least error.  In fact, it almost exactly predicted every observation in my validation data set.

####Conclusion

Given the high degree of accuracy of the random forest model, I used it to predict `classe` values for the `pml-testing.csv` data set.  And that model was able to correctly predict all 20 test observations.

####Appendix

#####Decision Tree Fit Summary - Figure 1

```{r, echo=FALSE, results="hide", warning = FALSE, message=FALSE}
library(RCurl)

trainCSV <- getURL("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",ssl.verifypeer = FALSE)
testCSV <- getURL("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",ssl.verifypeer = FALSE)

train <- read.csv(text = trainCSV,header=TRUE)
test <- read.csv(text = testCSV,header=TRUE)

##Remove incomplete columns.
complete.col <- logical(160)

for (i in 1:160) {

  if (any(is.na(train[,i]))) {
		
		complete.col[i] <- FALSE
	
	} else if(!(any(is.numeric(train[,i])))) {

		complete.col[i] <- FALSE

	} else {

		complete.col[i] <- TRUE

	}

	complete.col[c(1,3,4)] <-FALSE

	complete.col[c(2,6,160)] <-TRUE

}

train.complete <- train[,complete.col]

test.complete <- test[,complete.col]

library(caret)
library(AppliedPredictiveModeling)

set.seed(3333)
inTrain = createDataPartition(train.complete$classe, p = .6)[[1]]
train.complete.train = train.complete[inTrain,]
train.complete.validate = train.complete[-inTrain,]

tree <- train(train.complete.train$classe ~ ., method = "rpart", data = train.complete.train)
ptree <- predict(tree,train.complete.validate)

lda <- train(train.complete.train$classe ~ ., method = "lda", data = train.complete.train)
plda <- predict(lda,train.complete.validate)

rfCtrl = trainControl(method = "cv", number = 4, allowParallel = TRUE, verboseIter = TRUE)
forest <- train(train.complete.train$classe ~ ., method = "rf", data = train.complete.train, trControl = rfCtrl)
pforest <- predict(forest,train.complete.validate)
```
```{r, echo=FALSE}
tree
```

#####Linear Disciminant Analysis Fit Summary - Figure 2

```{r, echo=FALSE}
lda
```

#####Random Forest Fit Summary - Figure 3

```{r, echo=FALSE}
forest
```

#####Linear Disciminant Analysis Confusion Matrix Output - Figure 4

```{r, echo=FALSE}
confusionMatrix(train.complete.validate$classe,plda)
```

#####Random Forest Confusion Matrix Output - Figure 5

```{r, echo=FALSE}
confusionMatrix(train.complete.validate$classe,pforest)
```
